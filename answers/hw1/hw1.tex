\documentclass[11pt]{article}
\usepackage[UTF8]{ctex}
\usepackage[a4paper]{geometry}
\geometry{left=2.0cm,right=2.0cm,top=2.5cm,bottom=2.5cm}

\usepackage{comment}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{diagbox}
\usepackage{amsmath,amsfonts,graphicx,amssymb,bm,amsthm}
%\usepackage{algorithm,algorithmicx}
\usepackage[ruled]{algorithm2e}
\usepackage[noend]{algpseudocode}
\usepackage{fancyhdr}
\usepackage{tikz}
\usepackage{graphicx}
\usetikzlibrary{arrows,automata}
\usepackage{hyperref}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=blue,      
	urlcolor=blue,
	citecolor=cyan,
}			

\setlength{\headheight}{14pt}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.5 em}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem*{definition*}{Definition}

\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\hfill$\blacktriangleleft$\end{trivlist}}
\newenvironment{answer}[1][Answer]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1.}\hskip \labelsep]}{\hfill$\lhd$\end{trivlist}}

\newcommand\E{\mathbb{E}}
\newcommand\per{\mathrm{per}}


\title{Homework \#1}
\usetikzlibrary{positioning}

\begin{document}

\pagestyle{fancy}
\lhead{Peking University}
\chead{}
\rhead{Mathematical Foundations for the Information Age, 2024 Fall}

\begin{center}
    {\LARGE \bf Homework \#1}\\
    {Due: 2024-9-30 23:59 \quad$|$\quad 8 Problems, 100 Pts}\\
    {Name: 徐靖, ID: 2200012917}            % Write down your name and ID here.
\end{center}



\begin{problem}{1 (8')}
Define
\begin{align*}
    \Gamma(s) = \int_{0}^{+\infty} x^{s - 1} \mathrm{e}^{-x} \mathrm{d}x.
\end{align*}
where $s>0$. It can be proved that $\Gamma(s)$ is well-defined (You don't need to prove this).
\begin{itemize}
    \item [(1)] (4') Prove that, $\Gamma(s+1)=s\Gamma(s)$.
    \item [(2)] (4') Prove that,
    \begin{align*}
        \Gamma(s)=2\int_{0}^{+\infty}x^{2s-1}\mathrm{e}^{-x^2}\mathrm{d}x.
    \end{align*}
\end{itemize}
\end{problem}

\begin{answer} ~
\begin{itemize}
    \item [(1)] 
$$\begin{align*}
s\Gamma(s)&=\int_{0}^{+\infty}sx^{s-1}\mathrm e^{-x}\mathrm dx\\
&=\int_{0}^{+\infty}\mathrm e^{-x}\mathrm dx^s\\
&=\mathrm e^{-x}x^s\Big|_0^{+\infty}-\int_{0}^{+\infty}x^{s}\mathrm d\mathrm e^{-x}\\
&=\int_{0}^{+\infty}x^{s}\mathrm e^{-x}\mathrm dx\\
&=\Gamma(s+1)
\end{align*}$$
    \item [(2)] 
$$\begin{align*}
2\int_{0}^{+\infty}x^{2s-1}\mathrm{e}^{-x^2}\mathrm{d}x &= \int_{0}^{+\infty}2t^{s-\frac{1}{2}}\mathrm e^{-t}\mathrm d \sqrt{t} \quad (t=x^2)\\
&= \int_{0}^{+\infty}2t^{s-1}\mathrm e^{-t}\mathrm dt\\
&= \Gamma (s)
\end{align*}$$
\end{itemize}
\end{answer}



\begin{problem}{2 (10')}
Define a random variable $Q \sim \chi^2(k)$ $(k\in\mathbb{Z}_+)$ if $Q=Z_1^2+\cdots+Z_k^2$ where $Z_1,\cdots,Z_k \sim \mathcal{N}(0,1)$ are independent random variables. Given two independent random variables $X\sim\chi^2(m),\;Y\sim\chi^2(n)$ $(m,n\in\mathbb{Z}_+,\;m > n)$.
\begin{itemize}
    \item [(1)] (4') Calculate the value of $\mathbb{E}(X)$.
    \item [(2)] (2') Prove that, $X + Y \sim \chi^2(m + n)$.
    \item [(3)] (4') Does $X - Y \sim \chi^2(m - n)$? Prove your result.
\end{itemize}
\end{problem}

\begin{answer} ~
\begin{itemize}
    \item [(1)]
$$\begin{align*}
\mathbb{E}(X) &=\mathbb{E}\left(\sum_{i=1}^m X_i^2 \right)\\
&=m \mathbb D(X_1^2)\\
&=m
\end{align*}$$
    \item [(2)]
$$\begin{align*}&X=\sum_{i=1}^m X_i^2,Y=\sum_{i=1}^n Y_i^2\\
\Rightarrow& X+Y=\sum_{i=1}^m X_i^2+\sum_{i=1}^n Y_i^2\end{align*}$$
Since $\{X_i\}_m,\{Y_i\}_n$ are independent variables, $X+Y \sim \chi^2(m+n)$
    \item [(3)] 
$$\begin{align*}&X=\sum_{i=1}^m X_i^2,Y=\sum_{i=1}^n Y_i^2\\
\Rightarrow& X-Y=\sum_{i=1}^m X_i^2-\sum_{i=1}^n Y_i^2\end{align*}$$
Given that $\{X_i\}_m,\{Y_i\}_n$ are independent variables, we have
$$\mathrm{D}(X-Y)=\sum_{i=1}^m \mathrm D(X_i^2)+\sum_{i=1}^n \mathrm D(Y_i^2)=M+N\neq M-N$$
Thus $X-Y \sim \chi^2(m-n)$ is wrong
\end{itemize}
\end{answer}



\begin{problem}{3 (8')} In this problem, we will prove two basic probability inequalities. You will use these inequalities frequently in this course, so make sure you are familiar with them, including the statements and conditions.
\begin{itemize}
    \item [(1)] (4') (Markov Inequality) Suppose $X$ is a non-negative random variable and $\mathbb{E}(X)<+\infty$. Prove that, for any $a>0$,
    \begin{align*}
        \mathbb{P}(X\geq a)\leq\frac{\mathbb{E}(X)}{a}.
    \end{align*}
    \item [(2)] (4') (Chebyshev Inequality) Suppose $X$ is a random variable with $\mathbb{E}(X)<+\infty, Var(X)<+\infty$. Prove that, for any $a>0$,
    \begin{align*}
        \mathbb{P}(|X-\mathbb{E}(X)|\geq a)\leq\frac{Var(X)}{a^2}.
    \end{align*}
\end{itemize}
\end{problem}

\begin{answer} ~
\begin{itemize}
    \item [(1)] 
$$\mathbb E(X)=\int_0^{+\infty} xp(x)\mathrm dx\ge \int_a^{+\infty} xp(x)\mathrm dx\ge a\int_a^{+\infty} p(x)\mathrm dx=a\mathbb P(X\ge a)$$
    \item [(2)] 
$$\mathbb P(|X-\mathbb E(X)|\ge a)=\mathbb P(|X-\mathbb E(X)|^2\ge a^2)\leq \frac{\mathbb E(|X-\mathbb E(X)|^2)}{a^2}=\frac{Var(X)}{a^2}$$
\end{itemize}
\end{answer}



\begin{problem}{4 (14')}
In this problem, we will prove the following Chernoff bound (Theorem \ref*{thm:chernoff}).
\begin{theorem}[Chernoff Bound]
\label{thm:chernoff}
    Suppose $X_1,\cdots,X_n$ are independently Bernoulli random variables with expectation $p\in(0,1)$. Then for any $\varepsilon\in(0,1-p)$,
    \begin{align*}
        \mathbb{P}\left(\frac{1}{n}\sum_{i=1}^n X_i\geq p+\varepsilon\right)\leq \exp\left[-nD_B(p+\varepsilon||p)\right] \leq \exp(-2n\varepsilon^2),
    \end{align*} 
where 
\begin{align*}
    D_B(p||q):=p\ln\frac{p}{q}+(1-p)\ln\frac{1-p}{1-q}.
\end{align*}
\end{theorem}
\begin{itemize}
    \item [(1)] (5') Under the conditions of Theorem \ref*{thm:chernoff}, prove that for any $t>0$,
    \begin{align*}
        \mathbb{P}\left(\sum_{i=1}^n X_i\geq n(p+\varepsilon)\right)\leq\mathbb{E}\left(\mathrm{e}^{t\sum_{i=1}^n X_i}\right)\cdot\mathrm{e}^{-nt(p+\varepsilon)}.
    \end{align*}
    \item [(2)] (9') Finish the proof of Theorem \ref*{thm:chernoff}.
\end{itemize}
\end{problem}

\begin{answer} ~
\begin{itemize}
    \item [(1)] 
$$\begin{align*}\mathbb P\left(\frac{1}{n}\sum_{i\in [n]} X_i-\mathbb E(X) \ge \epsilon\right)&=\mathbb P(\mathrm e^{t\sum_{i\in [n]} X_i}\ge \mathrm e^{tn(p+\epsilon)})\\
&\leq \mathbb E(\mathrm e^{t\sum_{i\in [n]} X_i})\mathrm e^{-nt(p+\epsilon)}\end{align*}$$
    \item [(2)] 
Given that,
$$\mathbb E(\mathrm e^{t\sum_{i\in [n]} X_i})=\Pi_{i\in [n]}\mathbb E(\mathrm e^{tX_i})=(p\mathrm e^t+1-p)^n$$
And we have,
$$\inf_{t>0} \mathbb (p\mathrm e^t+1-p)^n\mathrm e^{-nt(p+\epsilon)}=\mathrm e^{-nD_B(p+\epsilon\|p)}$$
Consider the function $f(\epsilon)=2\epsilon^2-D_B(p+\epsilon\|p)$,
$$f'=4\epsilon+\ln \frac{(1-p-\epsilon)p}{(p+\epsilon)(1-p)}$$
$$f''=4-\frac{1}{1-p-\epsilon}-\frac{1}{p+\epsilon}\ge 0$$
Thus,
$$f'\ge f'(0)=0,f\ge f(0)=0$$
In conclusion,
$$\mathbb P\left(\frac{1}{n}\sum_{i\in [n]} X_i-\mathbb E(X) \ge \epsilon\right) \leq \mathrm e^{-nD_B(p+\epsilon\|p)}\leq \mathrm e^{-2n\epsilon^2}$$
\end{itemize}
\end{answer}



\begin{problem}{5 (12')} ~
\begin{itemize}
    \item [(1)] (3') For what value of $d$ does the volume $V(d)$ of a $d$-dimensional unit ball take on its maximum? You don't need to prove your result.
    \item [(2)] (4') Consider drawing a random point $x$ from the unit ball in $\mathbb{R}^d$ (surface and interior) uniformly at random. What's the variance of $x_1$ (the first coordinate of $x$)? You don't need to prove your result.
    \item [(3)] (5') Recall the way we generate a random unit vector in $d$ dimensions. First, generate $d$ i.i.d samples $v_i\;(i\in [d])$ from a Gaussian distribution with $\mu=0$ and $\sigma^2=1$. Then, define the vector $v$ as $v=[v_1,v_2,...,v_d]$. Finally, return $\frac{v}{||v||_2}$, where $||v||_2=\sqrt{\sum_{i=1}^d v_i^2}$. Briefly explain why it generates a unit vector uniformly at random.
\end{itemize}
\end{problem}

\begin{answer} ~
\begin{itemize}
    \item [(1)] $d=5$
    \item [(2)] $\mathbb D(x_1)=\frac{1}{d+2}$
    \item [(3)]  Since the Gaussian distribution is rotationally symmetric in any number of dimensions ,$v$ was sampled isotropically. the normalization step ensures that the resulting unit vector is uniformly distributed over the surface of the unit sphere in $d$-dimensional space. Thus, the probability of any unit vector pointing in a particular direction is the same.
\end{itemize}
\end{answer}



\begin{problem}{6 (12')}
A 3-dimensional cube has vertices, edges and faces. In a $d$-dimensional cube, these components are called faces. A vertex is a $0$-dimensional face, an edge a $1$-dimensional face, etc. Answer the following problems. You don't need to prove your result.
\begin{itemize}
    \item [(1)] (3') For $0\leq k\leq d$, how many $k$-dimensional faces does a $d$-dimensional cube have?
    \item [(2)] (3') What is the total number of faces of all dimensions? The $d$-dimensional face is the cube itself which you can include in your count.
    \item [(3)] (3') What is the surface area of a unit cube in $d$-dimensions (a unit cube has side-length one in each dimension)?
    \item [(4)] (3') What is the surface area of the cube if the length of each side was 2?
\end{itemize}
\end{problem}

\begin{answer} ~
\begin{itemize}
    \item [(1)] 
0-dimension faces of a $d$-dimension cube can form a set :
$$A=\left\{(x_1,x_2,...,x_d)\big|x_i\in \{1/2,-1/2\}\right\}$$
A $k$-dimensional face can be described by a subset of A consisting of all the vertices of the face. In fact, these vertices traverse k dimensions of the cube, and the coordinates of the other $d-k$ dimensions are the same. That means the number of $k$-dimensional faces is :
$$\binom{d}{k}2^{d-k}$$
    \item [(2)] 
The total number is 
$$\sum_{i\in [d]}\binom{d}{i}2^{d-i}=3^d$$
    \item [(3)]
The surface area of ​​a $d$-dimensional cube is the sum of the volumes of its $d-1$-dimensional faces, and each $d-1$-dimensional face is a $d-1$-dimensional cube. Thus we have,
$$A(d)=\binom{d}{d-1}2^{d-(d-1)}V(d-1)=2d$$
    \item [(4)]
    When length of each side was 2, we have,
$$A=\binom{d}{d-1}2^{d-(d-1)}V(d-1)*2^{d-1}=d\cdot2^d$$
\end{itemize}
\end{answer}



\begin{problem}{7 (16')}
Consider the upper hemisphere of a unit-radius ball in $d$-dimensions. What is the height of the maximum volume cylinder that can be placed entirely inside the hemisphere?

\textit{[Hint: You need to consider all possible placement options.]}
\end{problem}

\begin{answer}

Consider all cylinders that can be inscribed in a $d$-dimensional unit hemisphere. We aim to prove that the volume of all such cylinders does not exceed that of two specific types of cylinders: 
$A=$ the cylinder whose base is tangent to the equator and whose top intersects the surface of the unit sphere, 
$B=$ the cylinder whose side is tangent to the equator and whose base is perpendicular to the equator, intersecting the surface of the unit sphere.

\textbf{Lemma} : All cylinders that can be inscribed in a $d$-dimensional unit hemisphere are contained within a unit hemisphere of radius $\leq 1$ in the form of $A$ or $B$.

\textbf{Proof of the Lemma:}
\begin{itemize}
    \item Consider one base of the cylinder. If this base does not intersect the unit hemisphere, we can translate it until it intersects, letting the intersection point be $X$ (which may also be a high-dimensional manifold).
    \item Center the expansion of the cylinder at $X$ until a second intersection point $Y$ exists, ensuring $X \cap Y = \emptyset$.
\end{itemize}
We only need to show that the transformed cylinder satisfies the lemma:
\begin{itemize}
    \item If both $X$ and $Y$ are on the equator, then one base of the cylinder is tangent to the equator. Using the center of the base as the center of the hemisphere, the maximum distance from this point to the other base can be constructed as a radius for the unit hemisphere. Thus, the cylinder is contained in the form of $A$, and the radius of this hemisphere is $\leq$ the shortest distance from the center to the unit hemisphere, which is $\leq 1$.
    
    \item If both $X$ and $Y$ are on the surface of the unit sphere, we can similarly construct a unit hemisphere that contains the cylinder in the form of $A$. This is intuitive (since the forms $A$ and $B$ provide the largest possible volumes for the cylinder).
    
    \item If $X$ is on the surface of the unit sphere and $Y$ is on the equator, then the cylinder is contained in the form of $B$.
\end{itemize}

The lemma is proven.

\textbf{Main conclusion:}

Assuming the height of the cylinder is $h$, we consider the maximum volumes in cases $A$ and $B$:
\[
V_A(h,d) = h \times V(d-1) \left(\sqrt{1 - h^2}\right)^{d-1}
\]
\[
V_B(h,d) = h \times V(d-1) \left(\frac{\sqrt{1 - (h/2)^2}}{2}\right)^{d-1}
\]
Taking the derivative with respect to $h$, we find:
\[
V_A(h,d) \leq V_A\left(\frac{1}{\sqrt{d}}, d\right) = (d-1)^{\frac{d-1}{2}} d^{-d/2} V(d-1)
\]
\[
V_B(h,d) \leq V_B\left(\frac{2}{\sqrt{d}}, d\right) = 2^{2-d} (d-1)^{\frac{d-1}{2}} d^{-d/2} V(d-1)
\]
Assuming $d \geq 3$, the maximum volume of the cylinder placed in the form of $A$ with height $\frac{1}{\sqrt{d}}$ is obtained.

\end{answer}



\begin{problem}{8 (20')} 
Consider the following geometries in $d$-dimensional space:
\begin{align*}
    \Phi_d=\left\{(x_1,\cdots,x_d)\mid x_1^2+\cdots+x_d^2\leq 1\right\}\qquad
    \Omega_d=\left\{(x_1,\cdots,x_d)\mid |x_1|+\cdots+|x_d|\leq 1\right\}
\end{align*}
\begin{itemize}
    \item [(1)] (6') Consider the following two random processes:
    \begin{itemize}
        \item Pick two uniformly random unit vectors $x,y$ from the sphere in $d$ dimension.
        \item Pick a uniformly random plane passing through the origin in $d$ dimensions. Then pick two uniformly random unit vectors $w,z$ from the 2D sphere lying on that plane.
    \end{itemize}
    Determine whether $x$ and $w$ are identically distributed, and whether the pairs $(x,y)$ and $(w,z)$ are identically distributed. Briefly explain the reasons.
    \item [(2)] (6') Suppose $x$ and $y$ are sampled independently from $\Phi_d$. Denote random variable $Z=x^\top y$. Calculate $Var(Z)$.
    \item [(3)] (8') Calculate $V(\Omega_d)$ (the volume of $\Omega_d$) and $A(\Omega_d)$ (the surface area of $\Omega_d$).
\end{itemize}
\end{problem}

\begin{answer} ~
\begin{itemize}
    \item [(1)] 
$x,w$ are identially distributed because they are all uniformly random unit vectors in $d$ dimension.
$(x,y), (w,z)$ are identially distributed because they are all pairs of uniformly random unit vectors in $d$ dimension. In fact $(x,y)$ is also in a plane.
    \item [(2)] 
Let $y$ be a vector along the positive direction of the $x_1$ axis.
$$Z=x^Ty=|x||y|\cos\theta_1$$
Given that each component of direction vector $\theta=(\theta_1,\theta_2,\dots,\theta_d)$ is identically distributed,thus we have,
$$\mathbb E(\cos^2 \theta_1)=\frac{\sum_{i\in [d]}\mathbb E(\cos^2\theta_n)}{d}=\frac{\mathbb E(\sum_{i\in [d]} \cos^2\theta_n)}{d}=\frac{1}{d}$$
Given that $\Phi_d$ is Isotropic, we have:
$$\mathbb E(Z^2)=\mathbb E(\|X\|)^2\mathbb E(\cos^2\theta_1)$$
and,
$$\mathbb E(Z)=\mathbb E(|X|)^2\mathbb E(\cos\theta_1)=0$$
In $\Phi_d$, $\mathbb P(r=r_0)=\frac{A(\Phi_d)}{V(\Phi_d)}r_0^{d-1}=dr_0^{d-1}$, thus we have,
$$\mathbb E(\|X\|)^2=\mathbb E(r^2)=\int_{0}^{1}r_0^2\mathbb P(r=r_0)\mathrm dr_0=\frac{d}{d+2}$$
In conclusion,
$$\mathbb D(Z)= \mathbb E(Z^2)-\mathbb E(Z)^2=\mathbb E(\|X\|)^2\mathbb E(\cos^2\theta_1)=\left(\frac{d}{d+2}\right)^2\frac{1}{d}=\frac{d}{(d+2)^2}$$
    \item [(3)]
Define $V(\Phi_d,R)=V(\left\{(x_1,\cdots,x_d)\mid |x_1|+\cdots+|x_d|\leq R\right\})$, $A(\Phi_d,R)=A(\left\{(x_1,\cdots,x_d)\mid |x_1|+\cdots+|x_d|\leq R\right\})$. And we find,
$$V(\Phi_d,R)=V(\Phi_d)R^d,\quad A(\Phi_d,R)=A(\Phi_d)R^{d-1}$$
For $t=x_d\in [-1,1]$,
$$\begin{align*}V(\Phi_d)&=\left|\int_{-1}^{1}V(\left\{(x_1,\cdots,x_{d-1})\mid |x_1|+\cdots+|x_{d-1}|\leq 1-|t|\right\})\mathrm dt \right|\\ &= 2\left|\int_{0}^1 V(\Phi_{d-1},1-t)\mathrm dt\right|\\&=2V(\Phi_{d-1})\left|\int_{0}^{1}(1-t)^{d-1}\mathrm dt \right|\\&=\frac{2V(\Phi_{d-1})}{d}\end{align*}$$
$$\begin{align*}A(\Phi_d)&=\left|\int_{-1}^{1}V(\left\{(x_1,\cdots,x_{d-1})\mid |x_1|+\cdots+|x_{d-1}|\leq 1-|t|\right\})\mathrm dt \right|\\ &= 2\left|\int_{0}^1 A(\Phi_{d-1},1-t)\mathrm dt\right|\\&=2A(\Phi_{d-1})\left|\int_{0}^{1}(1-t)^{d-1}\mathrm dt \right|\\&=\frac{2A(\Phi_{d-1})}{d}\end{align*}$$
Given that $V(\Phi_{2})=2$, we find
$$V(\Phi_d)=\frac{2^d}{d!}$$
About $A(\Phi_d)$, we have
$$\begin{align*}V(\Phi_d)&=\left|\int\mathrm dV(\Phi_d) \right|=\left|\int_{0}^{1}\frac{A(\Phi_d,t)}{\sqrt{d}}\mathrm dt \right|\\ &=\frac{A(\Phi_{d})}{\sqrt{d}}\left|\int_{0}^{1}(1-t)^{d-1}\mathrm dt \right|\\&=\frac{A(\Phi_{d})}{d\sqrt{d}}\end{align*}$$
Thus, 
$$A(\Phi_d)=\frac{\sqrt{d}\cdot 2^{d}}{(d-1)!}$$
\end{itemize}
\end{answer}



\end{document}